{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rOfMhZJqh99S",
        "F0p5zyIsTm5p",
        "Bcr346vSp5Vi",
        "uTuRfnxn84Tz"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prkhar05/Tiny_Text2SQL/blob/main/sql_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "vK0tyZq23Nk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "ApldlB5NuViq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLt6AyIUzcBd"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset,concatenate_datasets,Dataset,DatasetDict\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "edksL8Y5zfsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name1=\"b-mc2/sql-create-context\"\n",
        "dataset_name2=\"Clinton/Text-to-sql-v1\"\n",
        "dataset_name3=\"zerolink/zsql-sqlite-dpo\"\n",
        "dataset_name4=\"spider\"\n",
        "dataset_name5=\"PipableAI/pip-txt-to-sql-spider-bird-dataset\"\n",
        "dataset_name6=\"gretelai/synthetic_text_to_sql\"\n",
        "dataset_name7='NumbersStation/NSText2SQL'"
      ],
      "metadata": {
        "id": "Ak7N9n5i7nIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loading(dataset_name):\n",
        "  d = load_dataset(dataset_name)\n",
        "  dataset=d[list(d.keys())[0]]\n",
        "  keys=list(d.keys())\n",
        "  keys.pop(0)\n",
        "  for key in keys:\n",
        "    dataset=concatenate_datasets([dataset,d[key]])\n",
        "  print(f\"Some info of {dataset_name}\")\n",
        "  print(dataset.shape)\n",
        "  print(dataset.column_names)\n",
        "  print(dataset[0])\n",
        "  return dataset\n",
        "def prepare_dataset(dataset,rename_columns,remove_columns):\n",
        "  # dataset = load_dataset(dataset_name)\n",
        "  # dataset=dataset['train']\n",
        "  for column in rename_columns:\n",
        "    dataset = dataset.rename_column(column[0],column[1])\n",
        "  dataset = dataset.remove_columns(remove_columns)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "67WgbVwncfv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rawdataset1=loading(dataset_name1)\n",
        "rawdataset2=loading(dataset_name2)\n",
        "rawdataset3=loading(dataset_name3)\n",
        "rawdataset5=loading(dataset_name5)\n",
        "rawdataset6=loading(dataset_name6)"
      ],
      "metadata": {
        "id": "FYshp1pQeyWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1=prepare_dataset(rawdataset1,[['context','schema'],['answer','query']],[])\n",
        "dataset2=prepare_dataset(rawdataset2,[['input','schema'],['response','query'],['instruction','question']],['source', 'text'])\n",
        "dataset3=prepare_dataset(rawdataset3,[['rejected','query']],['chosen', 'weight'])\n",
        "dataset5=prepare_dataset(rawdataset5,[],[])\n",
        "dataset6=prepare_dataset(rawdataset6,[['sql_context','schema'],['sql','query'],['sql_prompt','question']],['id', 'domain', 'domain_description', 'sql_complexity', 'sql_complexity_description', 'sql_task_type', 'sql_task_type_description', 'sql_explanation'])"
      ],
      "metadata": {
        "id": "BwN9YvA7fFez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset7=load_dataset(dataset_name7)\n",
        "dataset7=dataset7['train']\n",
        "dataset7=pd.DataFrame(dataset7)\n",
        "splt=\"-- Using valid SQLite, answer the following questions for the tables provided above.\\n\\n--\"\n",
        "schema=[]\n",
        "question=[]\n",
        "for data in dataset7['instruction']:\n",
        "  d=data.split(splt)\n",
        "  schema.append(d[0])\n",
        "  question.append(d[1])\n",
        "data = {'schema': schema, 'question': question, 'query': dataset7['output']}\n",
        "dataset7 = pd.DataFrame(data, columns=['schema', 'question', 'query'])\n",
        "dataset7=dataset7.drop(2)"
      ],
      "metadata": {
        "id": "-rWCKT2ENzYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.concat([pd.DataFrame(dataset1),pd.DataFrame(dataset2),pd.DataFrame(dataset3),pd.DataFrame(dataset5),pd.DataFrame(dataset6),dataset7]).drop_duplicates(subset=['question'])\n",
        "dataset = Dataset.from_pandas(dataset)\n",
        "dataset"
      ],
      "metadata": {
        "id": "MLvEQiZUP0ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.push_to_hub(\"Cynaptics/Test2Sql\")"
      ],
      "metadata": {
        "id": "LLItKBljW5DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# splitting dataset"
      ],
      "metadata": {
        "id": "rOfMhZJqh99S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=load_dataset(\"Cynaptics/Test2Sql\")\n",
        "dataset=dataset['train']\n",
        "d=pd.DataFrame(dataset)\n",
        "d=d.drop(columns=[\"__index_level_0__\"])"
      ],
      "metadata": {
        "id": "bFF0IPaDYQRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_numbers_1000 = random.sample(range(1, 489956), 1000)\n",
        "random_numbers_10000 = random.sample(range(1, 489956), 10000)"
      ],
      "metadata": {
        "id": "RQQjuzmShlFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_train=d.iloc[random_numbers_10000]\n",
        "small_validation=d.iloc[random_numbers_1000]"
      ],
      "metadata": {
        "id": "gsdMTnzFf99Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=DatasetDict({\n",
        "    \"train\":dataset,\n",
        "    \"small_train\":Dataset.from_pandas(small_train),\n",
        "    \"small_validation\":Dataset.from_pandas(small_validation)\n",
        "})\n",
        "dataset"
      ],
      "metadata": {
        "id": "NhKEc1I4itLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.push_to_hub(\"Cynaptics/Test2Sql\")"
      ],
      "metadata": {
        "id": "F3jUon1ikD9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#conversion"
      ],
      "metadata": {
        "id": "F0p5zyIsTm5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=load_dataset(\"Cynaptics/Test2Sql\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "aH6L6VKOIVjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_pip_sql(schema,question,query):\n",
        "  prompt = f\"\"\"<schema>{schema}</schema>\n",
        "    <question>{question}</question>\n",
        "    <sql>{query}</sql>\"\"\"\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "MnOzKrNX73EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['small_validation']['schema'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcjvvSUFp1Tv",
        "outputId": "a2bc5c22-a18b-422a-a4ed-5be12d49dd8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CREATE TABLE table_name_28 (date VARCHAR, week VARCHAR)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "dicti={}\n",
        "for key in tqdm.tqdm(dataset.keys()):\n",
        "  dicti[key]={}\n",
        "  dicti[key]['prompt'] =[prompt_pip_sql(schema,question,query) for (schema,question,query) in zip(dataset[key]['schema'],dataset[key]['question'],dataset[key]['query'])]\n",
        "  dicti[key]=Dataset.from_dict(dicti[key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWqa6A38ImMS",
        "outputId": "8a30f63b-5576-4b61-d586-1948497b6dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:10<00:00,  2.18s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dicti=DatasetDict(dicti)\n",
        "dicti"
      ],
      "metadata": {
        "id": "J7hLexqKpg9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicti.push_to_hub(\"Cynaptics/Test2Sql_InstructionTuned\")"
      ],
      "metadata": {
        "id": "np-5SUnWLFIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#overview"
      ],
      "metadata": {
        "id": "Bcr346vSp5Vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# num=0\n",
        "# for data in dataset1:\n",
        "#   schema=data['schema']\n",
        "#   filtered=dataset2.filter(lambda d: d['schema']==schema)\n",
        "#   num+=filtered.shape[0]\n",
        "# num"
      ],
      "metadata": {
        "id": "dRF2NLfkjdIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concat=concatenate_datasets([dataset1,dataset2,dataset3,dataset5])\n",
        "# d=pd.DataFrame(concat)\n",
        "# # # d=d[['question','schema']]\n",
        "# duplics=d.duplicated(subset=['question'])\n",
        "# # duplics=d.duplicated()\n",
        "# duplics.sum()"
      ],
      "metadata": {
        "id": "abfKsJy-jdGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# d[duplics]"
      ],
      "metadata": {
        "id": "CK9SyTotyTRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def func(data):\n",
        "#   if(data['question']==\"What are the lowest points with 2013 as the year, and goals less than 0?\"):\n",
        "#     print(data)\n",
        "# dataset.filter(func)"
      ],
      "metadata": {
        "id": "qsOduN0TZoNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# duplics=d[d['query'].str.len()>65].duplicated(subset=['question'])\n",
        "# d[d['query'].str.len()>65][duplics]"
      ],
      "metadata": {
        "id": "v17zoeiKZuEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group=d[duplics].groupby('schema')\n",
        "# group.sum()\n",
        "# group.count()"
      ],
      "metadata": {
        "id": "bU5oyawSqnZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# queries=pd.DataFrame(dataset['query'],columns=['query'])\n",
        "# queries['length']=queries['query'].apply(len)"
      ],
      "metadata": {
        "id": "Bp3-MUMZ3SUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# d.sort_values(by='length',ascending=False)"
      ],
      "metadata": {
        "id": "Dk75vX9dcbYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# queries.sort_values(by='lenght', ascending=False)\n",
        "# queries.describe()\n",
        "# 174640=>(...,300)\n",
        "# 16532=>(300,500)\n",
        "# 9414=>(500,1000)\n",
        "# 1238=>(1000,2000)\n",
        "# 70=>(2000,3000)\n",
        "# 12=>(3000,...)\n",
        "\n",
        "# print(d[(d['length'] <= 300)].shape[0])\n",
        "# print(d[(d['length'] >= 300) & (d['length'] <= 500)].shape[0])\n",
        "# print(d[(d['length'] >= 500) & (d['length'] <= 1000)].shape[0])\n",
        "# print(d[(d['length'] >= 1000) & (d['length'] <= 2000)].shape[0])\n",
        "# print(d[(d['length'] >= 2000) & (d['length'] <= 3000)].shape[0])\n",
        "# print(d[(d['length'] >= 3000)].shape[0])"
      ],
      "metadata": {
        "id": "7OVruypE416Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# where=0\n",
        "# group=0\n",
        "# order=0\n",
        "# join=0\n",
        "# having=0\n",
        "# distinct=0\n",
        "# limit=0\n",
        "# union=0\n",
        "# offset=0\n",
        "# like=0\n",
        "# _in=0\n",
        "# between=0\n",
        "# _case=0\n",
        "# exists=0\n",
        "\n",
        "# def func(query):\n",
        "#   global where, group, order, join, having, distinct, limit, union, offset,like, _in, _case, between, exists\n",
        "#   query=query.split(' ')\n",
        "#   if \"WHERE\" in query:\n",
        "#     where=where+1\n",
        "#   if \"GROUP\" in query:\n",
        "#     group=group+1\n",
        "#   if \"ORDER\" in query:\n",
        "#     order=order+1\n",
        "#   if \"JOIN\" in query:\n",
        "#     join=join+1\n",
        "#   if \"HAVING\" in query:\n",
        "#     having=having+1\n",
        "#   if \"DISTINCT\" in query:\n",
        "#     distinct=distinct+1\n",
        "#   if \"LIMIT\" in query:\n",
        "#     limit=limit+1\n",
        "#   if \"UNION\" in query:\n",
        "#     union=union+1\n",
        "#   if \"OFFSET\" in query:\n",
        "#     offset=offset+1\n",
        "#   if \"LIKE\" in query:\n",
        "#     like=like+1\n",
        "#   if \"IN\" in query:\n",
        "#     _in=_in+1\n",
        "#   if \"BETWEEN\" in query:\n",
        "#     between=between+1\n",
        "#   if \"CASE\" in query:\n",
        "#     _case=_case+1\n",
        "#   if \"EXISTS\" in query:\n",
        "#     exists=exists+1\n",
        "\n",
        "# d['query'].map(func)\n",
        "# print(f\"where {where},group {group},order {order},join {join},having {having},distinct {distinct},limit {limit},union {union},offset {offset},like {like},between {between},exists {exists},case {_case},in {_in}\")\n",
        "\n",
        "# # where 176657,group 27972,order 36733,join 39510,having 1800,distinct 11548,limit 15878,union 309,offset 1052,like 8189,between 5119,exists 0,case 396,in 18801"
      ],
      "metadata": {
        "id": "I3XPL6pw3slV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# spider"
      ],
      "metadata": {
        "id": "uTuRfnxn84Tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown"
      ],
      "metadata": {
        "id": "gjkevqc_87Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1mkCx2GOFIqNesD4y8TDAO1yX1QZORP5w/view?usp=sharing  #test suite dataset\n",
        "# https://drive.usercontent.google.com/open?id=1iRDVHLr4mX2wQKSgA9J8Pire73Jahh0m&authuser=0 #spider dataset\n",
        "# https://drive.usercontent.google.com/open?id=1Y3ydpFiQQ3FC0bzdfy3groV95O_f1nXF&authuser=0 #cosql dataset\n",
        "# https://drive.usercontent.google.com/open?id=1Uu7NMHTR1tdQw1t7bAuM7OPU4LElVKfg&authuser=0 #sparc dataset\n",
        "spider_id=\"1iRDVHLr4mX2wQKSgA9J8Pire73Jahh0m\"\n",
        "spider_file=\"spiderdatasets\"\n",
        "\n",
        "cosql_id=\"1Y3ydpFiQQ3FC0bzdfy3groV95O_f1nXF\"\n",
        "cosql_file=\"cosqldatasets\"\n",
        "\n",
        "sparc_id=\"1Uu7NMHTR1tdQw1t7bAuM7OPU4LElVKfg\"\n",
        "sparc_file=\"sparcdatasets\""
      ],
      "metadata": {
        "id": "n0nQZCGJzi6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -q spiderdatabases.zip -d spiderdatabases/"
      ],
      "metadata": {
        "id": "QfS8P4mR9A8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import json\n",
        "def download_zip(file_id,output_file):\n",
        "    gdown.download(f'https://drive.google.com/uc?id={file_id}', output_file, quiet=False)\n",
        "def extract_zip(file_name) :\n",
        "    with zipfile.ZipFile(f\"/content/{file_name}.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(f\"{file_name}/\")\n",
        "def _zip(file_id,output_file):\n",
        "    download_zip(file_id,f'{output_file}.zip')\n",
        "    extract_zip(output_file)"
      ],
      "metadata": {
        "id": "leBiUYi8ziyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_zip(spider_id,spider_file)\n",
        "_zip(cosql_id,cosql_file)\n",
        "_zip(sparc_id,sparc_file)"
      ],
      "metadata": {
        "id": "6u2B_If69A-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=load_dataset(\"Cynaptics/Test2Sql\")\n",
        "dataset=dataset['train']"
      ],
      "metadata": {
        "id": "P9jlX74sBKkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/sparcdatasets/sparc/dev.json\", 'r') as f:\n",
        "    data = f.read()\n",
        "    data=json.loads(data)"
      ],
      "metadata": {
        "id": "NU-Yb9aXPrrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func(data):\n",
        "  if(data['question']==\"What is the start date of each appointment?\"):\n",
        "    print(data)\n",
        "dataset.filter(func)"
      ],
      "metadata": {
        "id": "5uEY-uIPB4YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data),type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVlm94BFCog5",
        "outputId": "521e3fc1-d16e-4d1e-fbab-88de4d5f6b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(422, list)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "id": "s4wIl7UOGJsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for d in data:\n",
        "  l.append(d['question'])\n",
        "len(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlvTnyiLI2LI",
        "outputId": "b2b523d1-f035-4443-e36b-715fedbd9c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2147"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([pd.DataFrame(dataset['question']),pd.DataFrame(l)]).duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nJxSTucJATf",
        "outputId": "fe0a8fff-db98-4c03-a819-c81d3d0c6712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list(data.keys())[1]\n",
        "# for key in data['24Egz2cFCmN77SbNs'].keys():\n",
        "#   print(key,data['24Egz2cFCmN77SbNs'][key])"
      ],
      "metadata": {
        "id": "kFy_ZqXTE9RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/spiderdatabase/spider/database/academic/schema.sql\", 'r') as sql_file:\n",
        "    sql_commands = sql_file.read()\n",
        "    print(sql_commands)"
      ],
      "metadata": {
        "id": "5VxIT9Ji9A6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('/content/database/database/academic/academicv1223round10group0.sqlite')\n",
        "\n",
        "# Create a cursor object to execute SQL queries\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Query to retrieve all table names\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "\n",
        "# Fetch all rows from the query result\n",
        "tables = cursor.fetchall()\n",
        "\n",
        "# Print the retrieved table names\n",
        "for table in tables:\n",
        "    print(table[0])\n",
        "\n",
        "# Close the cursor and connection\n",
        "cursor.close()\n",
        "conn.close()\n"
      ],
      "metadata": {
        "id": "IiLiPlhM9WGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('/content/database/database/academic/academicv1223round10group3.sqlite')\n",
        "\n",
        "# Create a cursor object to execute SQL queries\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Example: Retrieve and print the contents of a specific table\n",
        "table_name = 'author'  # Replace 'your_table_name' with the actual table name\n",
        "# cursor.execute(\"INSERT INTO author (aid, homepage, name, oid) VALUES (2, 'http://www.mm.com', 'John', 1002);\")\n",
        "cursor.execute(f\"SELECT * FROM {table_name}\")\n",
        "\n",
        "# Fetch all rows from the query result\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "# Print the column names\n",
        "column_names = [description[0] for description in cursor.description]\n",
        "print(\"Column names:\", column_names)\n",
        "\n",
        "# Print the retrieved rows\n",
        "for row in rows:\n",
        "    print(row)\n",
        "\n",
        "# Close the cursor and connection\n",
        "cursor.close()\n",
        "conn.close()\n"
      ],
      "metadata": {
        "id": "vi1Pe8T_9WEr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}